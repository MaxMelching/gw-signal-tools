# ----- Standard Lib Imports -----
from typing import Optional, Any, Callable, Literal

from copy import deepcopy

# ----- Third Party Imports -----
import numpy as np
from scipy.integrate import simpson
from scipy.optimize import minimize

from gwpy.timeseries import TimeSeries
from gwpy.frequencyseries import FrequencySeries
from gwpy.testing.utils import assert_quantity_equal
import astropy.units as u

# ----- Local Package Imports -----
from gw_signal_tools import preferred_unit_system, logger
from .waveform_utils import (
    td_to_fd_waveform, pad_to_get_target_df, restrict_f_range,
    get_signal_at_target_df, get_signal_at_target_frequs
)
from .test_utils import allclose_quantity, assert_allclose_quantity

__doc__ = """
Implementation of noise-weighted inner product that is
common in GW data analysis and helpers for computation.
"""


def inner_product(
    signal1: TimeSeries | FrequencySeries,
    signal2: TimeSeries | FrequencySeries,
    psd: Optional[FrequencySeries] = None,
    f_range: Optional[list[float] | list[u.Quantity]] = None,
    df: Optional[float | u.Quantity] = None,
    optimize_time_and_phase: bool = False,
    optimize_time: bool = False,
    optimize_phase: bool = False,
    min_dt_prec: Optional[float] = None,
    return_opt_info: bool = False
) -> u.Quantity | tuple[u.Quantity, dict[Literal['match_series', 'peak_phase',
    'peak_time'], u.Quantity | TimeSeries]]:
    r"""
    Calculates the noise-weighted inner product

    .. math:: \langle a, b \rangle = 2 \Re \int_{-\infty}^{\infty}
        \frac{\tilde{a}(f) \tilde{b}^*(f)}{S_n(f)} \, df
    
    of two signals using their representations
    :math:`\tilde{a}(f), \tilde{b}(f)` in frequency domain.
    
    In case of a `psd` :math:`S_n(f)` that is equal to 1 at all
    frequencies (the default case), this corresponds to the :math:`L^2`
    inner product.

    Parameters
    ----------
    signal1 : ~gwpy.timeseries.TimeSeries or
    ~gwpy.frequencyseries.FrequencySeries
        First signal
    signal2 : ~gwpy.timeseries.TimeSeries or
    ~gwpy.frequencyseries.FrequencySeries
        Second signal
    psd : ~gwpy.frequencyseries.FrequencySeries, optional,
    default = None
        Power spectral density to use in inner product. If None, it is
        taken to be 1 1/Hz at all frequencies. The frequency range of
        this default PSD is [-2048 Hz, 2048 Hz], so in case larger
        ranges shall be used, a custom PSD with suitable frequencies
        has to be provided.
    f_range : list[float] or list[~astropy.units.Quantity], optional,
    default = None
        Frequency range to compute inner product over. Is potentially
        cropped if bounds are greater than frequency range of one of the
        input signals.

        The whole argument can be None, otherwise it must have length 2.
        However, one of the bounds (or both) can still be None, which
        indicates that no boundary shall be set. If no bound is given,
        automatic bounds are computed from the frequency ranges of the
        input signals and `psd`. Note that conditioned waveforms might
        have a larger range than the one specified during waveform
        generation. For this reason, giving `f_range` may be very
        important.
    df : float or ~astropy.units.Quantity, optional, default = None
        Distance df between samples in frequency domain to use in
        integration.
        If None, it is set to 0.0625 Hz (or whatever frequency unit is
        used in the signals), which is the default df of frequency
        domain waveforms generated by `~lalsimulation.gwsignal`.
    optimize_time_and_phase : bool, optional, default = False
        Determines if a match is computed or just a "regular" inner
        product. The match will be optimized over relative time and
        phase shifts between `signal1` and `signal2`.

        It is also possible to optimize separately over time or phase
        shifts by using the arguments `optimize_time`, `optimize_phase`.
        Note, however, that `optimize_time_and_phase=True` will
        override `optimize_time=False` and `optimize_phase=False`.
    return_opt_info : boolean, optional, default = False
        Whether or not to return a dictionary with additional
        information about the optimization results. Contains the full
        time series of match values at all time shifts that are not
        optimized over phase yet.

        Has no effect if no optimization is not carried out.

    Returns
    -------
    ~astropy.units.Quantity or tuple[~astropy.units.Quantity, dict[str,
    ~gwpy.timeseries.TimeSeries | ~astropy.units.Quantity]]
        Inner product value with `signal1`, `signal2` inserted.
        Additional information if optimization is carried out and
        `return_opt_info=True`. More details on the latter are provided
        in the documentaiton of the `optimized_inner_product` function.

    Raises
    ------
    TypeError
        In case either one of `signal1`, `signal2`, `psd` has wrong type.
    ValueError
        In case format of `f_range` parameter is not correct.

    See also
    --------
    gw_signal_tools.waveform_utils.td_to_fd_waveform :
        Used to convert ``TimeSeries`` input to a ``FrequencySeries``.
    gwpy.frequencyseries.frequencyseries.interpolate :
        Function used to get signals to same sampling rate.
    
    Notes
    -----
    Some tips regarding the `df` parameter:
    (i) It should not be too large, otherwise results of the inner
    product may be erroneous.
    (ii) If chosen very small (e.g. in range of 0.001Hz), you should
    consider selecting only powers of two like 2**-10 Hz because these
    work best with certain function calls that utilize the Fourier
    transform of the involved signals. An indicator this might be
    necessary is a shape mismatch error.
    """
    # ----- Handling of units -----
    if isinstance(signal1, FrequencySeries):
        frequ_unit = signal1.frequencies.unit
    elif isinstance(signal1, TimeSeries):
        frequ_unit = signal1.times.unit * u.Hz / u.s
    else:
        raise TypeError(
            '`signal2` has to be a GWpy ``TimeSeries`` or ``FrequencySeries``.'
        )

    if isinstance(signal2, FrequencySeries):
        assert frequ_unit == signal2.frequencies.unit, \
            'Need consistent frequency/time units for `signal1` and `signal2`.'
    elif isinstance(signal2, TimeSeries):
        assert frequ_unit == signal2.times.unit * u.Hz / u.s, \
            'Need consistent frequency/time units for `signal1` and `signal2`.'
    else:
        raise TypeError(
            '`signal2` has to be a GWpy ``TimeSeries`` or ``FrequencySeries``.'
        )
    
    # ----- Handling PSD -----
    if psd is None:
        from .PSDs import psd_no_noise

        psd = psd_no_noise.copy()

        # Make sure units are consistent with input. PSD is always a density,
        # i.e. strain per frequency
        psd.override_unit(1 / frequ_unit)  # TODO: change to strain/Hz once lal updates are incorporated
        if (psd_frequ_unit := psd.frequencies.unit) != frequ_unit:
            psd.frequencies *= (frequ_unit / psd_frequ_unit)
    
    if isinstance(psd, FrequencySeries):
        assert frequ_unit == psd.frequencies.unit, \
            'Need consistent frequency/time units for `psd` and other signals.'
        
        assert 1 / frequ_unit == psd.unit, \
            ('Need valid psd units for psd, has to be strain per frequency.')
        # TODO: change to strain/Hz once lal updates are incorporated
    else:
        raise TypeError('`psd` has to be a GWpy ``FrequencySeries`` or None.')

    # ----- Handling df argument -----
    if df is None:
        df = 0.0625 * frequ_unit  # Default value of output of FDWaveform
    else:
        try:
            df = u.Quantity(df, unit=frequ_unit)
        except u.UnitConversionError:
            # Conversion only fails if df is already Quantity and has
            # non-matching unit, so we can assume that df.unit works
            raise ValueError(
                f'Need consistent frequency units for `df` ({df.unit}) and'
                f' signals ({frequ_unit}).'
            )

    # ----- If necessary, do fft (padding to ensure -----
    # ----- sufficient resolution in frequency domain) -----
    if isinstance(signal1, TimeSeries):
        signal1 = td_to_fd_waveform(pad_to_get_target_df(signal1, df))

    if isinstance(signal2, TimeSeries):
        signal2 = td_to_fd_waveform(pad_to_get_target_df(signal2, df))
        
    # ----- Handling frequency range -----
    f_lower, f_upper = [
        max([signal1.frequencies[0], signal2.frequencies[0], psd.frequencies[0]]),
        min([signal1.frequencies[-1], signal2.frequencies[-1], psd.frequencies[-1]])
    ]

    # If bounds are given, check that they fit the input data
    if f_range is not None:
        if len(f_range) != 2:
            raise ValueError(
                '`f_range` must contain lower and upper frequency bounds for'
                'integration. One of them or both can be `None`, but both'
                'have to be specified if `f_range` is given.'
            )
        
        # Check if both lower and upper are given or one of them is None
        if f_range[0] is not None:
            try:
                f_lower_new = u.Quantity(f_range[0], unit=frequ_unit)
            except u.UnitConversionError:
                # Conversion only fails if df is already Quantity and has
                # non-matching unit, so we can assume that df.unit works
                raise ValueError(
                    'Need consistent frequency units for `f_range` members'
                    f' ({f_range[0].unit}) and signals ({frequ_unit}).'
                )
        else:
            f_lower_new = f_lower
        
        if f_range[1] is not None:
            try:
                f_upper_new = u.Quantity(f_range[1], unit=frequ_unit)
            except u.UnitConversionError:
                # Conversion only fails if df is already Quantity and has
                # non-matching unit, so we can assume that df.unit works
                raise ValueError(
                    'Need consistent frequency units for `f_range` members'
                    f' ({f_range[1].unit}) and signals ({frequ_unit}).'
                )

            # TODO: implement check of f_max with Nyquist of signals -> needed?
        else:
            f_upper_new = f_upper

        # New lower bound must be greater than current lower bound,
        # otherwise no values for the range are available in signals
        if f_lower_new >= f_lower:
            f_lower = f_lower_new
        else:
            # Leave lower bound at f_lower, no update
            logger.info(
                f'Given lower bound of {f_lower_new} is smaller than '
                'values available from given signals. Taking a lower '
                f'bound of {f_lower} instead.'
            )

        # New upper bound must be smaller than current upper bound,
        # otherwise no values for the range are available in signals
        if f_upper_new <= f_upper:
            f_upper = f_upper_new
        else:
            # Leave upper bound at f_upper, no update
            logger.info(
                f'Given upper bound of {f_upper_new} is larger than '
                'values available from given signals. Taking an upper '
                f'bound of {f_upper} instead.'
            )

    # ----- Get signals to same frequencies, i.e. make df -----
    # ----- equal (if necessary) and then restrict range -----
    if not (optimize_time_and_phase or optimize_time or optimize_phase):
        target_range = np.arange(f_lower.value, f_upper.value + 0.9 * df.value, step=df.value) << frequ_unit

        signal1 = get_signal_at_target_frequs(signal1, target_range,
                                              fill_val=0.0 * signal1.unit)
        signal2 = get_signal_at_target_frequs(signal2, target_range,
                                              fill_val=0.0 * signal2.unit)
        psd = get_signal_at_target_frequs(psd, target_range,
                                          fill_val=1.0 * psd.unit)

        return inner_product_computation(signal1, signal2, psd)
    else:
        non_zero_range = [f_lower, f_upper]  # Ensure all signals are non-zero on same range

        # TODO: adjust df here? Maybe based on input for min_dt or so
        # Get estimate of length of signals (= maximum shift we have to take
        # into account), select df to represent this (?)
        # duration = 1./df.value  # Number of points times dt

        if f_lower >= 0.0 * frequ_unit:
            target_range = np.arange(0.0, f_upper.value + 0.9 * df.value, step=df.value) << frequ_unit
        else:
            f_limit = max(abs(f_lower), abs(f_upper))
            target_range = np.arange(-f_limit.value, f_limit.value + 0.9 * df.value, step=df.value) << frequ_unit

        signal1 = get_signal_at_target_frequs(
            signal1,
            target_range,
            fill_val=0.0 * signal1.unit,
            fill_bounds=non_zero_range
        )

        signal2 = get_signal_at_target_frequs(
            signal2,
            target_range,
            fill_val=0.0 * signal2.unit,
            fill_bounds=non_zero_range
        )

        psd = get_signal_at_target_frequs(
            psd,
            target_range,
            fill_val=1.0 * psd.unit,
            fill_bounds=non_zero_range
        )
        
        if optimize_time_and_phase:
            # Overwrite
            optimize_time = True
            optimize_phase = True

        return optimized_inner_product(
            signal1=signal1,
            signal2=signal2,
            psd=psd,
            optimize_time=optimize_time,
            optimize_phase=optimize_phase,
            min_dt_prec=min_dt_prec,
            return_opt_info=return_opt_info
        )

def inner_product_computation(
    signal1: FrequencySeries,
    signal2: FrequencySeries,
    psd: FrequencySeries
) -> u.Quantity:
    """
    Lower level function for inner product calculation. Assumes that
    signal conditioning has been done so that they contain values at the
    same frequencies and then carries out the actual computation.

    Parameters
    ----------
    signal1 : ~gwpy.frequencyseries.FrequencySeries
        First signal to put into inner product.
    signal2 : ~gwpy.frequencyseries.FrequencySeries
        Second signal to put into inner product.
    psd : ~gwpy.frequencyseries.FrequencySeries
        Power spectral density to use in inner product.

    Returns
    -------
    ~astropy.units
        Inner product value with `signal1`, `signal2` inserted.
    
    See also
    --------
    scipy.integrate.simpson : Used for evaluation of inner product.
    """
    # ----- Assure same distance of samples -----
    assert (allclose_quantity(signal1.df, psd.df, rtol=0.01)
            and allclose_quantity(signal2.df, psd.df, rtol=0.01)), \
        'Signals must have equal frequency spacing.'
    
    # Second step: make sure frequencies are sufficiently equal.
    # Maximum deviation allowed between the is given df, which
    # determines accuracy the signals have been sampled with.
    custom_error_msg = (
        'Frequency samples of input signals are not equal. This might be '
        'due to `df` being too large. If `df` is already small, consider '
        'choosing a (negative) power of two as these seem to work best.'
    )

    try:
        assert (allclose_quantity(signal1.frequencies, signal2.frequencies,
                                  atol=0.0, rtol=0.01)
                and allclose_quantity(signal1.frequencies, psd.frequencies,
                                      atol=0.0, rtol=0.01)), \
            custom_error_msg
    except ValueError:
        # Due to unequal sample size. Since this is automatically checked by
        # numpy, we can be sure that signal1.size = signal2.size = psd.size
        raise ValueError(custom_error_msg)
    
    output_unit = signal1.unit * signal2.unit / psd.unit * signal1.frequencies.unit
    try:
        # output_unit = output_unit.to_system(preferred_unit_system)[0]
        output_unit = output_unit.compose(units=preferred_unit_system)[0]
    except u.UnitsError:
        output_unit = output_unit.si
        # Resets scale only for units, not for value. Best we can do in that case
    # TODO: check if composing result into units=preferred_unit_system is
    # better option. In current way, we still only change scale etc. of unit

    return (4.0 if ((signal1.frequencies[0].value >= 0.0)
                    or (signal1.frequencies[-1].value <= 0.0)) else 2.0  # Check if one-sided or not
            ) * np.real(
        simpson(y=signal1 * signal2.conjugate() / psd, x=signal1.frequencies)
    ) * output_unit

def optimized_inner_product(
    signal1: FrequencySeries,
    signal2: FrequencySeries,
    psd: FrequencySeries,
    optimize_time: bool,
    optimize_phase: bool,
    min_dt_prec: Optional[float] = None,  # Or something like 1e-6 as default?
    return_opt_info: bool = False
) -> u.Quantity | tuple[u.Quantity, dict[Literal['match_series', 'peak_phase',
    'peak_time'], u.Quantity | TimeSeries]]:
    """
    Lower level function for inner product calculation. Assumes that
    signal conditioning has been done so that they contain values at the
    same frequencies and then carries out the actual computation.

    In contrast to `inner_product_computation`, this function optimizes
    the inner product over time and phase shifts.

    Parameters
    ----------
    signal1 : ~gwpy.frequencyseries.FrequencySeries
        First signal to put into inner product.
    signal2 : ~gwpy.frequencyseries.FrequencySeries
        Second signal to put into inner product.
    psd : ~gwpy.frequencyseries.FrequencySeries
        Power spectral density to use in inner product.
    TODO: describe optimize keywords briefly
    return_opt_info : boolean, optional, default = False
        Whether or not to return a dictionary with additional
        information about the optimization results. Contains the full
        time series of match values at all time shifts that are not
        optimized over phase yet.

    Returns
    -------
    ~astropy.units.Quantity or tuple[~astropy.units.Quantity, dict[
    Literal['match_series', 'peak_phase', 'peak_time'], ~astropy.units.
    Quantity | ~gwpy.timeseries.TimeSeries]]
        Output depends on the value of `return_opt_info`. If False (the
        default), only the optimized value of the inner product is
        returned. If True, a tuple of this value and a dictionary is
        returned. This dictionary contains:
        (i) a ``TimeSeries`` where values of the inner product for
        different relative time shifts between `signal1`, `signal2`
        are stored. Optimization over phase is not carried out in this
        return, but it can easily be done by taking the `.abs()` of the
        ``TimeSeries``. To get inner product values that are not
        optimized over phase, take `.real` of the ``TimeSeries``.
        (ii) time at which maximum value occurs in (i) if
        `optimize_time=True` or `optimize_time_and_phase=True`.
        Otherwise it is set to zero, which corresponds to no
        optimization over time shift. This number represents a shift t0
        from `signal1` to `signal2`, i.e. `signal1` is 'ahead in time'
        in the sense that `signal1(t) = signal2(t+t0)`.
        (iii) phase shift needed to get maximum of (i) at time (ii) if
        `optimize_phase=True` or `optimize_time_and_phase=True`, i.e.
        it is the phase that the complex match series returned in (i)
        has at the time returned in (ii).
        Otherwise it is set to zero, which corresponds to no
        optimization over phase (the real part of (i) is taken).

        In other words, one can obtain the same inner product value by
        calculating the non-optimized inner product between `signal1`
        and `signal2*np.exp(-2.j*np.pi*signal2.frequencies*time_shift
        + 1.j*phase_shift)`. Here, `time_shift` is the value returned
        in (ii), i.e. with key `'peak_time'`, and `phase_shift` the
        value returned in (iii), i.e. with key `'peak_phase'`.
    """
    frequ_unit = signal1.frequencies.unit

    # ----- First step: assure same distance of samples -----
    assert (allclose_quantity(signal1.df, psd.df, atol=0.0, rtol=1e-5)
            and allclose_quantity(signal2.df, psd.df, atol=0.0, rtol=1e-5)), \
        'Signals must have equal frequency spacing.'
    
    # ----- Second step: make sure all signals start at valid frequencies -----
    assert ((allclose_quantity(signal1.f0, 0.0 * frequ_unit, atol=0.0, rtol=0.0)
             and allclose_quantity(signal2.f0, 0.0 * frequ_unit, atol=0.0, rtol=0.0)
             and allclose_quantity(psd.f0, 0.0 * frequ_unit, atol=0.0, rtol=0.0))
            or (allclose_quantity(-signal1.f0, signal1.frequencies[-1], atol=signal1.df, rtol=0.0)
                and allclose_quantity(-signal2.f0, signal2.frequencies[-1], atol=signal2.df, rtol=0.0)
                and allclose_quantity(-psd.f0, psd.frequencies[-1], atol=psd.df, rtol=0.0))), \
        ('All signals must start either at f=0 or be symmetric around f=0, '
         'where the latter refers to the case of an odd sample size. For an '
         'even sample size, on the other hand, the number of samples for '
         'positive frequencies is expected to be one less than the number of '
         'samples for negative frequencies, in accordance with the format '
         'expected by `~numpy.fft.ifftshift`. Note that the conditions just'
         'mentioned do not apply to the case of a starting frequency f=0, '
         'where both even and odd sample sizes are accepted.')
    
    # ----- Third step: assure frequencies are sufficiently equal. -----
    # ----- Maximum deviation allowed between the is given df, which -----
    # ----- determines accuracy the signals have been sampled with. -----
    custom_error_msg = (
        'Frequency samples of input signals are not equal. This might be '
        'due to `df` being too large. If `df` is already small, consider '
        'choosing a (negative) power of two as these seem to work best.'
    )
    # Is perhaps because interpolate uses fft, which works best with powers of two
    try:
        assert_allclose_quantity(signal1.frequencies, signal2.frequencies,
                                 atol=0.0, rtol=0.01)
        assert_allclose_quantity(signal1.frequencies, psd.frequencies,
                                 atol=0.0, rtol=0.01)
    except ValueError:
        # Due to unequal sample size. Since this is automatically checked by
        # numpy, we can be sure that signal1.size = signal2.size = psd.size
        raise ValueError(custom_error_msg)
    
    # ----- Fourth step: computations -----
    dft_vals = (signal1 * signal2.conjugate() / psd)

    # Append zeros or bring into correct format so that ifft can be used.
    # The prefactor is added here already because it depends on the given
    # frequency range
    if np.isclose(0., dft_vals.f0.value, atol=0.5*dft_vals.df.value, rtol=0.):
        n_append = dft_vals.size - 1
        n_total = dft_vals.size + n_append
        dt = 1. / (n_total*signal1.df)

        if min_dt_prec is None:
            min_dt_prec = dt
        
        if dt > min_dt_prec:  # TODO: make sure min_dt_prec is Quantity
            n_required = np.ceil(1. / (min_dt_prec*signal1.df))
        else:
            n_required = n_total

        n_required = next_power_of_two(n_required)

        n_append = n_required - dft_vals.size
        
        full_dft_vals = 4.*np.append(dft_vals.value, np.zeros(n_append))
        dt = (1. / (full_dft_vals.size*signal1.df)).si
    else:
        n_append = 0
        n_total = dft_vals.size
        dt = 1. / (n_total*signal1.df)

        if min_dt_prec is None:
            min_dt_prec = dt
        
        if dt > min_dt_prec:  # TODO: make sure min_dt_prec is Quantity
            n_required = np.ceil(1. / (min_dt_prec*signal1.df))
        else:
            n_required = n_total

        n_required = next_power_of_two(n_required)
        # -> is this worth it here? Operation-wise (in case dt is already big enough)

        n_append = n_required - dft_vals.size

        # if dft_vals.size % 2 == 0:
        if n_append % 2 == 0:
            # Symmetric appending
            n_append_lower = n_append_upper = n_append//2
        else:
            # Odd means start or beginning is larger
            if -dft_vals.f0 > dft_vals.frequencies[-1]:
                n_append_lower = n_append//2
                n_append_upper = n_append//2 + 1
            else:
                n_append_lower = n_append//2 + 1
                n_append_upper = n_append//2

        dft_vals = np.append(np.append(np.zeros(n_append_lower), dft_vals.value),
                             np.zeros(n_append_upper))

        dt = (1. / (dft_vals.size*signal1.df)).si
        
        full_dft_vals = 2.*np.fft.ifftshift(dft_vals)

        # full_dft_vals = 2.*np.fft.ifftshift(dft_vals.value)  # From before

        # TODO: check when to take .value, in ifftshift or in appending

    # TODO: not use .si, but .compose? Or at least try this?

    output_unit = signal1.unit * signal2.unit / psd.unit * signal1.frequencies.unit    
    try:
        # output_unit = output_unit.to_system(preferred_unit_system)[0]
        output_unit = output_unit.compose(units=preferred_unit_system)[0]
    except u.UnitsError:
        output_unit = output_unit.si
        # Resets scale only for units, not for value. Best we can do in that case

    match_series = TimeSeries(
        np.fft.ifft(full_dft_vals / dt.value),  # Discrete -> continuous
        unit=output_unit,
        t0=0.*dt.unit,
        dt=dt
    )

    # Handle wrap-around of signal
    number_to_roll = match_series.size // 2  # Arbitrary value, no deep meaning
    match_series = np.roll(match_series, shift=number_to_roll)
    match_series.shift(-match_series.times[number_to_roll])

    if optimize_phase:
        _match_series = match_series.abs()
    else:
        _match_series = match_series.real
    
    if optimize_time:
        peak_index = np.argmax(_match_series)
        match_result = _match_series[peak_index]
        peak_time = _match_series.times[peak_index]
    else:
        # Evaluation at t0=0 corresponds to usual inner product
        peak_time = 0.*match_series.times.unit
        peak_index = np.searchsorted(match_series.xindex.value,
                                     peak_time.value, side="left")
        match_result = _match_series[peak_index]
    
    if return_opt_info:
        peak_phase = np.angle(match_series)[peak_index] if optimize_phase else 0.*u.rad

        return match_result, {'match_series': match_series,
                              'peak_phase': peak_phase,
                              'peak_time': peak_time}
    else:
        return match_result

def next_power_of_two(x):
    return 1 if x == 0 else int(2**np.ceil(np.log2(x)))

def norm(
    signal: TimeSeries | FrequencySeries,
    *args,
    **kwargs
) -> u.Quantity | tuple[u.Quantity, dict[Literal['match_series', 'peak_phase',
    'peak_time'], u.Quantity | TimeSeries]]:
    """
    Wrapper function for calculation of the norm of the given `signal`
    (i.e. square root of inner product between `signal` and `signal`,
    its SNR) as measured by the noise-weighted inner product
    implemented in `inner_product`.

    Parameters
    ----------
    signal : ~gwpy.timeseries.TimeSeries or
    ~gwpy.frequencyseries.FrequencySeries
        Signal to compute norm for.
    *args, **kwargs
        Additional arguments, will be passed to `inner_product` function.

    Returns
    -------
    ~astropy.units.Quantity or tuple[~gwpy.timeseries.TimeSeries,
    ~astropy.units.Quantity, ~astropy.units.Quantity]
        Norm of `signal`, i.e. square root of inner product of `signal`
        with itself.

        If `optimize_time_and_phase = True`, a tuple is returned that
        contains a ``TimeSeries``, the aforementioned norm and a time.
        See `optimized_inner_product` for details on the return.
    
    See also
    --------
    gw_signal_tools.inner_product.inner_product :
        Arguments are passed to this function for calculations.
    """
    out = inner_product(signal, signal, *args, **kwargs)

    if isinstance(out, u.Quantity):
        return np.sqrt(out)
    else:
        out[1]['match_series'] = np.sqrt(out[1]['match_series'])
        return np.sqrt(out[0]), out[1]

def overlap(
    signal1: TimeSeries | FrequencySeries,
    signal2: TimeSeries | FrequencySeries,
    *args,
    **kwargs
) -> u.Quantity | tuple[u.Quantity, dict[Literal['match_series', 'peak_phase',
    'peak_time'], u.Quantity | TimeSeries]]:
    """
    Wrapper for calculation of the overlap of two given signals as
    measured by the noise-weighted inner product implemented in
    `inner_product`. This means the signals are normalized to have unit
    norm (with respect to this inner product) and then inserted into
    `inner_product`.

    Parameters
    ----------
    signal1 : ~gwpy.timeseries.TimeSeries or
    ~gwpy.frequencyseries.FrequencySeries
        First signal.
    signal2 : ~gwpy.timeseries.TimeSeries or
    ~gwpy.frequencyseries.FrequencySeries
        Second signal.
    *args, **kwargs
        Additional arguments, will be passed to `inner_product` function.

    Returns
    -------
    ~astropy.units.Quantity or tuple[~gwpy.timeseries.TimeSeries,
    ~astropy.units.Quantity, ~astropy.units.Quantity]
        Overlap of `signal1` and `signal2`.

        If `optimize_time_and_phase = True`, a tuple is returned that
        contains a ``TimeSeries``, the aforementioned norm and a time.
        See `optimized_inner_product` for details on the return.
    
    See also
    --------
    gw_signal_tools.inner_product.inner_product :
        Arguments are passed to this function for calculations.
    """
    out = inner_product(signal1, signal2, *args, **kwargs)

    normalization = 1.0  # Default value

    if isinstance(norm1 := norm(signal1, *args, **kwargs), u.Quantity):
        normalization *= norm1
    else:
        normalization *= norm1[0]

    if isinstance(norm2 := norm(signal2, *args, **kwargs), u.Quantity):
        normalization *= norm2
    else:
        normalization *= norm2[0]


    if isinstance(out, u.Quantity):
        return out / normalization
    else:
        out[1]['match_series'] /= normalization
        return out[0] / normalization, out[1]


# ---------- Optimization of Inner Product over Arbitrary Parameters ----------
# TODO: put this into waveform_utils?
def test_hm(
    wf_params: dict[str, u.Quantity],
    wf_generator: Callable[[dict[str, u.Quantity]], FrequencySeries]
) -> bool:
    """
    Perform test whether or not higher modes are relevant for the chosen
    point in parameter space and waveform model. This is done by
    comparing the similarity of two waveforms, one with a certain value
    for the reference phase 'phi_ref' and the other one with 'phi_ref'
    equal to zero, but phase shifted by two times this value. If higher
    modes are relevant, these waveforms will have an overlap not equal
    to 1, which is the test that is performed.

    Parameters
    ----------
    wf_params : dict[str, ~astropy.units.Quantity]
        Point in parameter space that waveform is generated at.
    wf_generator : Callable[[dict[str, ~astropy.units.Quantity]],
    ~gwpy.frequencyseries.FrequencySeries]
        Routine to generate waveforms.

    Returns
    -------
    boolean
        Whether or not higher modes have a significant impact for the
        selected configuration.
    """
    phi_val = 0.76*u.rad  # Some arbitrary shift
    wf_phizero_shifted = wf_generator(wf_params | {'phi_ref': 0.*u.rad}) * np.exp(1.j*2*phi_val)
    wf_phinonzero = wf_generator(wf_params | {'phi_ref': phi_val})
    
    if overlap(wf_phizero_shifted, wf_phinonzero) > 0.999:
        # Arbitrary value, but should be sufficient to assess influence of HMs
        return False
    else:
        return True

def test_precessing(wf_params: dict[str, u.Quantity]) -> bool:
    """
    Perform test whether or not the given binary system is precessing.
    This is done by looking at the x-, y-values of the component spins
    of each binary and if one of them is non-zero, the system is taken
    to be precessing. While this might not cover all cases correctly, it
    is sufficient to serve the main purpose of this function, namely its
    use in the optimization of the overlap between waveforms, where the
    return is used to select the default parameters to optimize over.
    
    Note that this function is compatible with all input accepted by
    the `lalsimulation.gwsignal` module. That means (i) there is no need
    to actually specify the spin components (default values of zero for
    all are assumed) and (ii) components need not be specified in
    cartesian coordinates, can also be spherical.

    Parameters
    ----------
    wf_params : dict[str, ~astropy.units.Quantity]
        Point in parameter space that waveform is generated at.

    Returns
    -------
    boolean
        Whether or not the system is precessing.
    """
    # TODO: maybe test for valid spin config?
    for i in [1, 2]:
        # Check for cartesian components first
        for index in ['x', 'y']:
            try:
                # if wf_params[f'spin{i}{index}'] != 0.*u.dimensionless_unscaled:
                if (wf_params[f'spin{i}{index}'] != 0.*u.dimensionless_unscaled
                    and wf_params[f'spin{i}z'] != 0.*u.dimensionless_unscaled):
                    # Spins are not parallel to L and not in orbital plane
                    return True
            except KeyError:
                pass
        
        # TODO: spins might not be parallel to L, but can still cancel
        # and in that case, no precession!!!
        # -> but that also depends on mass, very specific... Just neglect?
    
        # No precession in cartesian components, but spherical ones might be given
        try:
            if wf_params[f'spin{i}_tilt'] % (np.pi*u.rad) != 0.*u.rad:
                return True
        except KeyError:
            pass
        
    return False

def get_default_opt_params(
    wf_params: dict[str, u.Quantity],
    wf_generator: Callable[[dict[str, u.Quantity]], FrequencySeries]
) -> list[str]:
    """
    Determine external parameters to optimize over for the given
    waveform configuration and generator. The "base set" consists of
    'tc' and 'psi', but more might be added depending on the outputs of
    `test_precessing` and `test_hm`.

    Parameters
    ----------
    wf_params : dict[str, ~astropy.units.Quantity]
        Point in parameter space that waveform is generated at.
    wf_generator : Callable[[dict[str, ~astropy.units.Quantity]],
    ~gwpy.frequencyseries.FrequencySeries]
        Routine to generate waveforms.

    Returns
    -------
    list[str]
        List of waveform parameters to optimize over.
    """
    default_opt_params = ['tc', 'psi']

    if (use_phi_ref_and_phi_jl := test_precessing(wf_params)):
        default_opt_params += ['phi_ref', 'phi_jl']
        # TODO: find good definition of phi_jl. Bilby seems to use it, but in
        # "wrong order": https://git.ligo.org/lscsoft/bilby/-/blob/master/bilby/gw/source.py#L649
    elif (use_phi_ref := test_hm(wf_params, wf_generator)):
        # Higher modes might still be relevant for non-precessing
        default_opt_params += ['phi_ref']
    
    return default_opt_params

def optimize_overlap(  # TODO: rename to optimize_mismatch?
    wf_params: dict[str, u.Quantity],
    fixed_wf_generator: Callable[[dict[str, u.Quantity]], FrequencySeries],
    vary_wf_generator: Callable[[dict[str, u.Quantity]], FrequencySeries],
    opt_params: Optional[str | list[str]] = None,
    **inner_prod_kwargs
) -> tuple[FrequencySeries, FrequencySeries, dict[str, u.Quantity]]:
    r"""
    Maximize the overlap between two waveforms at the given point in the
    parameter space. This is done by varying certain parameters for one
    of the waveform generators while keeping them fixed for the other
    waveform generator and then minimizing the mismatch (1-overlap).

    Parameters
    ----------
    wf_params : dict[str, ~astropy.units.Quantity]
        Set of parameters, some of which will be fixed while others are
        varied.
    fixed_wf_generator : Callable[[dict[str, ~astropy.units.Quantity]],
    ~gwpy.frequencyseries.FrequencySeries]
        Waveform generator for the first waveform that is fixed, i.e. it
        is only generated once.
    vary_wf_generator : Callable[[dict[str, ~astropy.units.Quantity]],
    ~gwpy.frequencyseries.FrequencySeries]
        Waveform generator for which the parameters will be varied, i.e.
        it will be called many times.
    opt_params : Optional[str | list[str]], optional, default = None
        Set of parameters to optimize the overlap over. If None, a set
        of external parameters is automatically determined by calling
        `get_default_opt_params`. However, internal parameters can also
        be part of the list.

        Must be in `wf_params` or `'tc'` (equivalent: `'time'`),
        `'psi'` (equivalent up to a factor: `'phase' = 2*'psi'`).
        The latter two are essentially global time and phase shifts,
        they enter in the waveform only as a factor
        :math:`exp(i \cdot 2 \psi - i \cdot 2 \pi \cdot f \cdot tc)`.
        Commonly used names for them are coalescence time and
        polarization angle.

        Note that it is also possible to optimize over phase and time
        by enabling optimization over phase and time in the inner
        product function (by passing keyword arguments like
        `optimize_time_and_phase=True`, will be given to inner product),
        which can have a more desirable behaviour compared to passing
        `'time'` and `'phase'` in `opt_params`. The corresponding result
        will also be part of the output, despite potentially not being
        part of `opt_params`.
        
    Returns
    -------
    tuple[~gwpy.frequencyseries.FrequencySeries, ~gwpy.frequencyseries.
    FrequencySeries, dict[str, ~astropy.units.Quantity]]
        A three-tuple consisting of (i) the waveform generated by
        `fixed_wf_generator` at `wf_params`, (ii) the optimized waveform
        generated by `vary_wf_generator` and (iii) a dictionary where
        the optimal values for all elements of `opt_params` are stored.
    """
    wf1 = fixed_wf_generator(wf_params)

    if opt_params is None:
        _opt_params = get_default_opt_params(wf_params, vary_wf_generator)
        
        return optimize_overlap(
            wf_params=wf_params,
            fixed_wf_generator=fixed_wf_generator,
            vary_wf_generator=vary_wf_generator,
            opt_params=_opt_params,
            **inner_prod_kwargs
        )
    elif isinstance(opt_params, str):
        _opt_params = [opt_params]

        return optimize_overlap(
            wf_params=wf_params,
            fixed_wf_generator=fixed_wf_generator,
            vary_wf_generator=vary_wf_generator,
            opt_params=_opt_params,
            **inner_prod_kwargs
        )
    else:
        _opt_params = np.array(opt_params)
        # List is better than set because it maintains order of elements

        # time and phase indices are accessed frequently, thus store
        if 'tc' in _opt_params:
            time_index = np.argwhere(_opt_params == 'tc')[0,0]

            if 'time' in _opt_params:
                raise ValueError('Providing both `\'tc\'` and `\'time\'` is not permitted.')
        elif 'time' in _opt_params:
            time_index = np.argwhere(_opt_params == 'time')[0,0]
        else:
            time_index = None
        
        if 'psi' in _opt_params:
            phase_index = np.argwhere(_opt_params == 'psi')[0,0]

            if 'phase' in _opt_params:
                raise ValueError('Providing both `\'psi\'` and `\'phase\'` is not permitted.')
        elif 'phase' in _opt_params:
            phase_index = np.argwhere(_opt_params == 'phase')[0,0]
        else:
            phase_index = None
        
        # Check if optimization in inner product is carried out
        if inner_prod_kwargs.get('optimize_time_and_phase', False) \
            or inner_prod_kwargs.get('optimize_time', False) \
            or inner_prod_kwargs.get('optimize_phase', False):
            _inner_prod_is_optimized = True
        else:
            _inner_prod_is_optimized = False
        
        if _inner_prod_is_optimized and \
            (time_index is not None or phase_index is not None):
            # logger.info(
            #     'Optimization in inner product is switched on, but so is '
            #     'numerical optimization over time and/or phase. This will '
            #     'most likely produce strange results.'
            # )

            logger.info(
                'Optimization in inner product is switched on, but so is '
                'numerical optimization over time and/or phase. Only the '
                'former will be conducted.'
            )

            opt_params = opt_params.copy()  # Otherwise popping bad

            if time_index is not None:
                opt_params.pop(time_index)
                time_index = None
            
            if phase_index is not None:
                opt_params.pop(phase_index)
                phase_index = None
            
            _opt_params = np.array(opt_params)
        
        # For internal use, make sure only one name is used for
        # time/tc and phase/psi. Reverted at the end
        if time_index is not None:
            _opt_params[time_index] = 'tc'

        if phase_index is not None:
            _opt_params[phase_index] = 'psi'

        if len(_opt_params) == 2 and time_index is not None \
            and phase_index is not None:
            # Optimize over global time and phase shifts only. In that case,
            # one can make things much faster by generating the waveform
            # beforehand and just multiplying with phase
            wf2 = vary_wf_generator(wf_params)

            def wf2_shifted(args):
                tc, psi = args[time_index], args[phase_index]
                return wf2 * np.exp(-2.j*np.pi*wf2.frequencies.value*tc + 2.j*psi)
        else:
            def wf2_shifted(args):
                wf_args = wf_params | {param: args[i]*wf_params[param].unit for i, param in enumerate(_opt_params) if (param != 'tc' and param != 'psi')}
                tc = wf_args.pop('tc', 0.)
                psi = wf_args.pop('psi', 0.)
                wf2 = vary_wf_generator(wf_args)
                return wf2 * np.exp(-2.j*np.pi*tc*wf2.frequencies.value + 2.j*psi)

    def loss(args):
        _match = overlap(wf1, wf2_shifted(args), **inner_prod_kwargs)
        if isinstance(_match, u.Quantity):
            return 1.-_match
        else:
            return 1.-_match[0]

    init_guess = [wf_params[param].value if (param != 'tc' and param != 'psi') else 0. for param in _opt_params]
    
    # if phase_index is not None and 'phi_ref' in _opt_params:
    #     init_guess[phase_index] = 0.1
    #     init_guess[np.argwhere(_opt_params == 'phi_ref')] = -0.1
    # Does not even seem to be necessary anymore, default selection makes sure
    # this is only done if needed
    
    bounds = len(_opt_params)*[(None, None)]
    if phase_index is not None:
        bounds[phase_index] = (-np.pi, np.pi)
        # bounds[phase_index] = (-2.*np.pi, 2.*np.pi)
    if 'phi_ref' in _opt_params:
        bounds[np.argwhere(_opt_params == 'phi_ref')[0,0]] = (-np.pi, np.pi)
        # bounds[np.argwhere(_opt_params == 'phi_ref')[0,0]] = (-2.*np.pi, 2.*np.pi)
    # At some point during testing, 2pi was better. But pi should be sufficient
    # because we use twice of this value each time. In principle, 0 to pi
    # should be sufficient as well because we cover full range 0 to 2pi then,
    # but if gradient points to negative phase values, but we bound there,
    # no optimization will be reached, so we allow for same negative range
    
    result = minimize(fun=loss, x0=init_guess, bounds=bounds,
                      method='Nelder-Mead')#, tol=1e-6, options=dict(fatol=1e-6, xatol=1e-6))
    # fatol is tolerable change in fun over subsequent iterations that
    # indicates convergence. 1e-5 should be sufficient
    # -> does not change behaviour much, so we just let automatic do its magic

    opt_params_results = {param: result.x[i] for i, param in enumerate(opt_params)}
    for param, param_val in wf_params.items():
        if param in opt_params_results:
            opt_params_results[param] *= param_val.unit

    # Add units to phase, time shifts and potentially revert renaming
    if time_index is not None:
        opt_params_results[opt_params[time_index]] *= u.s

    if phase_index is not None:
        opt_params_results[opt_params[phase_index]] *= u.rad

        if opt_params[phase_index] == 'phase':
            opt_params_results['phase'] *= 2

    logger.info(result.message
                + f' Remaining waveform mismatch is {result.fun:.5f}.')
    
    if _inner_prod_is_optimized:
        # For return of truly optimized waveform, time and phase have to
        # be optimized to respective values of optimized inner product result
        wf2 = wf2_shifted(result.x)

        _, opt_info = inner_product(wf1, wf2, **(inner_prod_kwargs | {'return_opt_info': True}))
        opt_params_results['time'] = tc = opt_info['peak_time']
        opt_params_results['phase'] = phic = opt_info['peak_phase']

        wf2 *= np.exp(-2.j*np.pi*tc*wf2.frequencies + 1.j*phic)
        # NOTE: if only time or phase is optimized, the respective other
        # value tc/phic will be zero, so it has no influence in that case

        # TODO: check if this is correct!!! Or if we should do minus of peak_phase or so
    else:
        wf2 = wf2_shifted(result.x)

    return wf1, wf2, opt_params_results
